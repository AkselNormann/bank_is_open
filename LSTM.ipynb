{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# use surprise for collaborative filtering\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-2013.pkl\n",
      "2013-2014.pkl\n",
      "(1265, 3, 508)\n",
      "(1272, 3, 508)\n",
      "2014-2015.pkl\n",
      "(2537, 3, 508)\n",
      "(1263, 3, 508)\n",
      "2015-2016.pkl\n",
      "(3800, 3, 508)\n",
      "(1269, 3, 508)\n",
      "2016-2017.pkl\n",
      "2017-2018.pkl\n"
     ]
    }
   ],
   "source": [
    "game_data_path = \"data/neural_net_data/\"\n",
    "files = sorted(os.listdir(game_data_path))\n",
    "\n",
    "files = [\"2012-2013.pkl\", \"2013-2014.pkl\", \"2014-2015.pkl\", \"2015-2016.pkl\",\"2016-2017.pkl\", \"2017-2018.pkl\"]\n",
    "\n",
    "X_train = np.zeros(5)\n",
    "\n",
    "for file in files[:-2]:\n",
    "    if \".pkl\" not in file: continue\n",
    "    \n",
    "    with open(game_data_path + file, 'rb') as f:\n",
    "        print(file)\n",
    "        if X_train.shape[0] == 5:\n",
    "            X_train, y_train = pickle.load(f, encoding='latin1')\n",
    "        else:\n",
    "            X_add, y_add = pickle.load(f, encoding='latin1')\n",
    "            print(X_train.shape)\n",
    "            print(X_add.shape)\n",
    "            X_train = np.concatenate((X_train, X_add), axis = 0)\n",
    "            y_train = np.concatenate((y_train, y_add), axis = 0)\n",
    "\n",
    "with open(game_data_path + files[-2], 'rb') as f:\n",
    "        print(files[-2])\n",
    "        X_val, y_val = pickle.load(f, encoding='latin1')\n",
    "        \n",
    "with open(game_data_path + files[-1], 'rb') as f:\n",
    "        print(files[-1])\n",
    "        X_test, y_test = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(X, y):\n",
    "    X = X[y > 0]\n",
    "    y = y[y > 0]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = clean_data(X_train, y_train)\n",
    "X_val, y_val = clean_data(X_val, y_val)\n",
    "X_test, y_test = clean_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Specify the model architecture\n",
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, target_size, num_layers, batch_size, time_steps, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.time_steps = time_steps\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Initialize LSTM unit\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=False)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2out = nn.Linear(hidden_dim, target_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size , hidden_dim)\n",
    "        return (torch.zeros(self.num_layers, self.time_steps, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.time_steps, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden = self.lstm(input_seq, self.hidden)\n",
    "        \n",
    "        drop_out = self.drop(lstm_out)\n",
    "        \n",
    "        pred = self.hidden2out(drop_out)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model\n",
    "model = LSTMModel(input_dim = 508,\n",
    "                     hidden_dim = 15,\n",
    "                     target_size = 1,\n",
    "                     num_layers = 2,\n",
    "                     batch_size = 10, \n",
    "                     time_steps = 3,\n",
    "                     dropout = 0.2\n",
    "                 )\n",
    "                     \n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Losses after 1 iterations:\n",
      "Train: 1255.0549522173835\n",
      "Val: 1041.327880859375\n",
      "----------\n",
      "Losses after 2 iterations:\n",
      "Train: 726.2589502594111\n",
      "Val: 746.7875366210938\n",
      "----------\n",
      "Losses after 3 iterations:\n",
      "Train: 597.5694204160125\n",
      "Val: 621.0652465820312\n",
      "----------\n",
      "Losses after 4 iterations:\n",
      "Train: 524.226513466415\n",
      "Val: 615.1679077148438\n",
      "----------\n",
      "Losses after 5 iterations:\n",
      "Train: 487.689893938221\n",
      "Val: 572.86083984375\n",
      "----------\n",
      "Losses after 6 iterations:\n",
      "Train: 463.28413303762017\n",
      "Val: 573.881591796875\n",
      "----------\n",
      "Losses after 7 iterations:\n",
      "Train: 440.418165153468\n",
      "Val: 506.3221740722656\n",
      "----------\n",
      "Losses after 8 iterations:\n",
      "Train: 414.465350570325\n",
      "Val: 476.4446716308594\n",
      "----------\n",
      "Losses after 9 iterations:\n",
      "Train: 401.25444685588604\n",
      "Val: 511.23443603515625\n",
      "----------\n",
      "Losses after 10 iterations:\n",
      "Train: 399.959305584659\n",
      "Val: 487.2259216308594\n",
      "----------\n",
      "Losses after 11 iterations:\n",
      "Train: 388.79255546626723\n",
      "Val: 477.43731689453125\n",
      "----------\n",
      "Losses after 12 iterations:\n",
      "Train: 383.78829184041774\n",
      "Val: 482.782470703125\n",
      "----------\n",
      "Losses after 13 iterations:\n",
      "Train: 383.4962020778675\n",
      "Val: 471.47601318359375\n",
      "----------\n",
      "Losses after 14 iterations:\n",
      "Train: 378.6271197890543\n",
      "Val: 458.5560607910156\n",
      "----------\n",
      "Losses after 15 iterations:\n",
      "Train: 372.8182150947065\n",
      "Val: 461.2293395996094\n",
      "----------\n",
      "Losses after 16 iterations:\n",
      "Train: 372.7864716538881\n",
      "Val: 467.7793884277344\n",
      "----------\n",
      "Losses after 17 iterations:\n",
      "Train: 373.7288457389513\n",
      "Val: 467.31402587890625\n",
      "----------\n",
      "Losses after 18 iterations:\n",
      "Train: 372.0338032635391\n",
      "Val: 467.1866149902344\n",
      "----------\n",
      "Losses after 19 iterations:\n",
      "Train: 371.6601296601529\n",
      "Val: 468.1960144042969\n",
      "----------\n",
      "Losses after 20 iterations:\n",
      "Train: 371.30324041716057\n",
      "Val: 460.69134521484375\n",
      "----------\n",
      "Losses after 21 iterations:\n",
      "Train: 372.29122439836016\n",
      "Val: 459.63153076171875\n",
      "----------\n",
      "Losses after 22 iterations:\n",
      "Train: 371.7045111522586\n",
      "Val: 463.70587158203125\n",
      "----------\n",
      "Losses after 23 iterations:\n",
      "Train: 370.8038401858409\n",
      "Val: 467.57513427734375\n",
      "----------\n",
      "Losses after 24 iterations:\n",
      "Train: 371.93769335386327\n",
      "Val: 459.4092712402344\n",
      "----------\n",
      "Losses after 25 iterations:\n",
      "Train: 371.2191679765562\n",
      "Val: 463.3317565917969\n",
      "----------\n",
      "Losses after 26 iterations:\n",
      "Train: 370.60669490873414\n",
      "Val: 463.31597900390625\n",
      "----------\n",
      "Losses after 27 iterations:\n",
      "Train: 370.5148152107434\n",
      "Val: 462.2123718261719\n",
      "----------\n",
      "Losses after 28 iterations:\n",
      "Train: 371.2955323603575\n",
      "Val: 467.13922119140625\n",
      "----------\n",
      "Losses after 29 iterations:\n",
      "Train: 371.2229395095342\n",
      "Val: 456.2750244140625\n",
      "----------\n",
      "Losses after 30 iterations:\n",
      "Train: 372.0497109663628\n",
      "Val: 466.299072265625\n",
      "----------\n",
      "Losses after 31 iterations:\n",
      "Train: 371.5041296992949\n",
      "Val: 463.22454833984375\n",
      "----------\n",
      "Losses after 32 iterations:\n",
      "Train: 371.4749147161027\n",
      "Val: 450.18975830078125\n",
      "----------\n",
      "Losses after 33 iterations:\n",
      "Train: 371.72376912968025\n",
      "Val: 463.6684265136719\n",
      "----------\n",
      "Losses after 34 iterations:\n",
      "Train: 371.0037943096657\n",
      "Val: 459.05267333984375\n",
      "----------\n",
      "Losses after 35 iterations:\n",
      "Train: 371.2434979442434\n",
      "Val: 454.2850341796875\n",
      "----------\n",
      "Losses after 36 iterations:\n",
      "Train: 371.44763533613946\n",
      "Val: 450.5668029785156\n",
      "----------\n",
      "Losses after 37 iterations:\n",
      "Train: 371.71394986746844\n",
      "Val: 456.367431640625\n",
      "----------\n",
      "Losses after 38 iterations:\n",
      "Train: 371.56357212908637\n",
      "Val: 464.2437438964844\n",
      "----------\n",
      "Losses after 39 iterations:\n",
      "Train: 370.6226969870606\n",
      "Val: 448.6307373046875\n",
      "----------\n",
      "Losses after 40 iterations:\n",
      "Train: 371.2151161967398\n",
      "Val: 455.3585205078125\n",
      "----------\n",
      "Losses after 41 iterations:\n",
      "Train: 370.8491983627076\n",
      "Val: 461.284912109375\n",
      "----------\n",
      "Losses after 42 iterations:\n",
      "Train: 371.35058756918465\n",
      "Val: 462.1559143066406\n",
      "----------\n",
      "Losses after 43 iterations:\n",
      "Train: 371.67734855078226\n",
      "Val: 466.75872802734375\n",
      "----------\n",
      "Losses after 44 iterations:\n",
      "Train: 371.38973718207586\n",
      "Val: 448.73883056640625\n",
      "----------\n",
      "Losses after 45 iterations:\n",
      "Train: 370.7525293741993\n",
      "Val: 459.4520568847656\n",
      "----------\n",
      "Losses after 46 iterations:\n",
      "Train: 371.9499910351154\n",
      "Val: 462.6070556640625\n",
      "----------\n",
      "Losses after 47 iterations:\n",
      "Train: 370.53621279426795\n",
      "Val: 454.02105712890625\n",
      "----------\n",
      "Losses after 48 iterations:\n",
      "Train: 372.0963798542941\n",
      "Val: 459.6531982421875\n",
      "----------\n",
      "Losses after 49 iterations:\n",
      "Train: 371.10258359242005\n",
      "Val: 457.5149841308594\n",
      "----------\n",
      "Losses after 50 iterations:\n",
      "Train: 371.5699340383556\n",
      "Val: 456.2785339355469\n",
      "----------\n",
      "Losses after 51 iterations:\n",
      "Train: 370.91723526852957\n",
      "Val: 454.4623718261719\n",
      "----------\n",
      "Losses after 52 iterations:\n",
      "Train: 371.8974472942479\n",
      "Val: 447.93328857421875\n",
      "----------\n",
      "Losses after 53 iterations:\n",
      "Train: 371.08257731995354\n",
      "Val: 459.9595947265625\n",
      "----------\n",
      "Losses after 54 iterations:\n",
      "Train: 370.8759238272515\n",
      "Val: 459.1121826171875\n",
      "----------\n",
      "Losses after 55 iterations:\n",
      "Train: 370.39726814034725\n",
      "Val: 456.4888610839844\n",
      "----------\n",
      "Losses after 56 iterations:\n",
      "Train: 371.3005124664768\n",
      "Val: 452.9552001953125\n",
      "----------\n",
      "Losses after 57 iterations:\n",
      "Train: 371.4745828120657\n",
      "Val: 464.6986389160156\n",
      "----------\n",
      "Losses after 58 iterations:\n",
      "Train: 370.5674380098853\n",
      "Val: 456.9749755859375\n",
      "----------\n",
      "Losses after 59 iterations:\n",
      "Train: 372.2378289750016\n",
      "Val: 455.7173156738281\n",
      "----------\n",
      "Losses after 60 iterations:\n",
      "Train: 370.9111891540638\n",
      "Val: 457.80938720703125\n",
      "----------\n",
      "Losses after 61 iterations:\n",
      "Train: 370.87675629400286\n",
      "Val: 459.70379638671875\n",
      "----------\n",
      "Losses after 62 iterations:\n",
      "Train: 371.23631680163135\n",
      "Val: 449.611572265625\n",
      "----------\n",
      "Losses after 63 iterations:\n",
      "Train: 371.3908896958532\n",
      "Val: 451.49346923828125\n",
      "----------\n",
      "Losses after 64 iterations:\n",
      "Train: 370.9265459134102\n",
      "Val: 465.14654541015625\n",
      "----------\n",
      "Losses after 65 iterations:\n",
      "Train: 371.64856274602295\n",
      "Val: 458.7881164550781\n",
      "----------\n",
      "Losses after 66 iterations:\n",
      "Train: 370.6360745175282\n",
      "Val: 453.2230529785156\n",
      "----------\n",
      "Losses after 67 iterations:\n",
      "Train: 370.50729550509845\n",
      "Val: 458.72857666015625\n",
      "----------\n",
      "Losses after 68 iterations:\n",
      "Train: 371.2413868503305\n",
      "Val: 457.6388244628906\n",
      "----------\n",
      "Losses after 69 iterations:\n",
      "Train: 371.05403525289614\n",
      "Val: 470.2628173828125\n",
      "----------\n",
      "Losses after 70 iterations:\n",
      "Train: 371.1907398429183\n",
      "Val: 455.9215087890625\n",
      "----------\n",
      "Losses after 71 iterations:\n",
      "Train: 371.556632548084\n",
      "Val: 462.24169921875\n",
      "----------\n",
      "Losses after 72 iterations:\n",
      "Train: 371.30640693884465\n",
      "Val: 466.7964172363281\n",
      "----------\n",
      "Losses after 73 iterations:\n",
      "Train: 370.8821835678399\n",
      "Val: 461.421142578125\n",
      "----------\n",
      "Losses after 74 iterations:\n",
      "Train: 370.76371140452164\n",
      "Val: 461.35614013671875\n",
      "----------\n",
      "Losses after 75 iterations:\n",
      "Train: 371.2344141934961\n",
      "Val: 457.7311706542969\n",
      "----------\n",
      "Losses after 76 iterations:\n",
      "Train: 371.4050777629844\n",
      "Val: 453.8173522949219\n",
      "----------\n",
      "Losses after 77 iterations:\n",
      "Train: 370.5840775563433\n",
      "Val: 453.7890930175781\n",
      "----------\n",
      "Losses after 78 iterations:\n",
      "Train: 371.8660787372093\n",
      "Val: 458.0041198730469\n",
      "----------\n",
      "Losses after 79 iterations:\n",
      "Train: 370.98327559056094\n",
      "Val: 464.2010192871094\n",
      "----------\n",
      "Losses after 80 iterations:\n",
      "Train: 370.69303789006153\n",
      "Val: 454.3794250488281\n",
      "----------\n",
      "Losses after 81 iterations:\n",
      "Train: 371.2000343554973\n",
      "Val: 449.92193603515625\n",
      "----------\n",
      "Losses after 82 iterations:\n",
      "Train: 371.0854901500441\n",
      "Val: 461.1177978515625\n",
      "----------\n",
      "Losses after 83 iterations:\n",
      "Train: 371.748194649344\n",
      "Val: 453.80169677734375\n",
      "----------\n",
      "Losses after 84 iterations:\n",
      "Train: 370.51606669442305\n",
      "Val: 465.2865295410156\n",
      "----------\n",
      "Losses after 85 iterations:\n",
      "Train: 370.3354515517053\n",
      "Val: 472.5312194824219\n",
      "----------\n",
      "Losses after 86 iterations:\n",
      "Train: 370.21153909644397\n",
      "Val: 456.3656005859375\n",
      "----------\n",
      "Losses after 87 iterations:\n",
      "Train: 370.9977880953493\n",
      "Val: 457.62164306640625\n",
      "----------\n",
      "Losses after 88 iterations:\n",
      "Train: 371.83635206478203\n",
      "Val: 462.2899475097656\n",
      "----------\n",
      "Losses after 89 iterations:\n",
      "Train: 370.3051643087075\n",
      "Val: 456.36529541015625\n",
      "----------\n",
      "Losses after 90 iterations:\n",
      "Train: 371.8454103444858\n",
      "Val: 457.0580749511719\n",
      "----------\n",
      "Losses after 91 iterations:\n",
      "Train: 371.3695997865996\n",
      "Val: 464.05157470703125\n",
      "----------\n",
      "Losses after 92 iterations:\n",
      "Train: 370.91067774933543\n",
      "Val: 461.3419494628906\n",
      "----------\n",
      "Losses after 93 iterations:\n",
      "Train: 371.3280537425931\n",
      "Val: 454.4581298828125\n",
      "----------\n",
      "Losses after 94 iterations:\n",
      "Train: 371.4498000711088\n",
      "Val: 454.3682861328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Losses after 95 iterations:\n",
      "Train: 370.3850030312733\n",
      "Val: 460.06634521484375\n",
      "----------\n",
      "Losses after 96 iterations:\n",
      "Train: 369.96007192281434\n",
      "Val: 465.0225524902344\n",
      "----------\n",
      "Losses after 97 iterations:\n",
      "Train: 371.27682116646315\n",
      "Val: 461.7191162109375\n",
      "----------\n",
      "Losses after 98 iterations:\n",
      "Train: 371.2206217791375\n",
      "Val: 463.70111083984375\n",
      "----------\n",
      "Losses after 99 iterations:\n",
      "Train: 370.58059830022563\n",
      "Val: 456.49420166015625\n",
      "----------\n",
      "Losses after 100 iterations:\n",
      "Train: 370.9482998301055\n",
      "Val: 458.39984130859375\n",
      "----------\n",
      "Losses after 101 iterations:\n",
      "Train: 370.77368158218576\n",
      "Val: 456.3157043457031\n",
      "----------\n",
      "Losses after 102 iterations:\n",
      "Train: 371.1057179763754\n",
      "Val: 460.3294982910156\n",
      "----------\n",
      "Losses after 103 iterations:\n",
      "Train: 370.1240917637184\n",
      "Val: 459.9916687011719\n",
      "----------\n",
      "Losses after 104 iterations:\n",
      "Train: 371.80735322213707\n",
      "Val: 469.43902587890625\n",
      "----------\n",
      "Losses after 105 iterations:\n",
      "Train: 371.13513349069024\n",
      "Val: 456.73504638671875\n",
      "----------\n",
      "Losses after 106 iterations:\n",
      "Train: 372.06151660087966\n",
      "Val: 452.9222717285156\n",
      "----------\n",
      "Losses after 107 iterations:\n",
      "Train: 370.86827480175447\n",
      "Val: 465.6537780761719\n",
      "----------\n",
      "Losses after 108 iterations:\n",
      "Train: 370.71635857005197\n",
      "Val: 454.4359436035156\n",
      "----------\n",
      "Losses after 109 iterations:\n",
      "Train: 370.315622946015\n",
      "Val: 454.1561279296875\n",
      "----------\n",
      "Losses after 110 iterations:\n",
      "Train: 370.8754130607409\n",
      "Val: 456.34075927734375\n",
      "----------\n",
      "Losses after 111 iterations:\n",
      "Train: 370.35696872802686\n",
      "Val: 467.530517578125\n",
      "----------\n",
      "Losses after 112 iterations:\n",
      "Train: 370.9417869861605\n",
      "Val: 459.46759033203125\n",
      "----------\n",
      "Losses after 113 iterations:\n",
      "Train: 370.86689171063466\n",
      "Val: 459.4802551269531\n",
      "----------\n",
      "Losses after 114 iterations:\n",
      "Train: 370.97622619764235\n",
      "Val: 456.06158447265625\n",
      "----------\n",
      "Losses after 115 iterations:\n",
      "Train: 371.1467760989945\n",
      "Val: 458.5637512207031\n",
      "----------\n",
      "Losses after 116 iterations:\n",
      "Train: 371.68731986262867\n",
      "Val: 465.6510009765625\n",
      "----------\n",
      "Losses after 117 iterations:\n",
      "Train: 370.977240283507\n",
      "Val: 459.281494140625\n",
      "----------\n",
      "Losses after 118 iterations:\n",
      "Train: 371.46671483555616\n",
      "Val: 453.9745178222656\n",
      "----------\n",
      "Losses after 119 iterations:\n",
      "Train: 371.42158374505715\n",
      "Val: 459.0251770019531\n",
      "----------\n",
      "Losses after 120 iterations:\n",
      "Train: 370.8697795579568\n",
      "Val: 449.944091796875\n",
      "----------\n",
      "Losses after 121 iterations:\n",
      "Train: 371.42353407727734\n",
      "Val: 462.0724182128906\n",
      "----------\n",
      "Losses after 122 iterations:\n",
      "Train: 371.25832462137777\n",
      "Val: 457.6781005859375\n",
      "----------\n",
      "Losses after 123 iterations:\n",
      "Train: 370.083536756685\n",
      "Val: 460.2132263183594\n",
      "----------\n",
      "Losses after 124 iterations:\n",
      "Train: 371.3960208865909\n",
      "Val: 460.42706298828125\n",
      "----------\n",
      "Losses after 125 iterations:\n",
      "Train: 370.8347199987293\n",
      "Val: 456.9601745605469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-a9e777915aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Step 3. Run our forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we only care about the last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-51440d89272b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdrop_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cs229proj/lib/python3.7/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(5000):\n",
    "    train_loss = 0\n",
    "    for i in range(0, len(X_train), model.batch_size):\n",
    "        if i + model.batch_size >= len(X_train) : continue\n",
    "        \n",
    "        #Pytorch accumulates gradients. We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM, detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network.\n",
    "        batch_input = X_train[i : i + model.batch_size] #.reshape((X.shape[1], model.batch_size, X.shape[2]))\n",
    "        batch = Variable(torch.from_numpy(batch_input)).type(torch.FloatTensor)\n",
    "                                                    \n",
    "        targets = Variable(torch.from_numpy(y_train[i : i + model.batch_size])).type(torch.FloatTensor)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        scores = model(batch)\n",
    "        scores = scores[:, -1].reshape((model.batch_size)) # we only care about the last output\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #optimizer.zero_grad()   # clear gradients for next train\n",
    "        \n",
    "        train_loss += loss.detach().numpy()\n",
    "        \n",
    "    ## validation loss\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\"----------\")\n",
    "        print(\"Losses after {} iterations:\".format(epoch + 1))\n",
    "        n_batches = len(X_train)/model.batch_size\n",
    "        print(\"Train: {}\".format(train_loss/n_batches))\n",
    "        with torch.no_grad():\n",
    "            batch = Variable(torch.from_numpy(X_val)).type(torch.FloatTensor)\n",
    "            targets = Variable(torch.from_numpy(y_val)).type(torch.FloatTensor)\n",
    "            scores = model(batch)\n",
    "            scores = scores[:, -1].reshape((len(y_val))) # we only care about the last output\n",
    "            val_loss = loss_function(scores, targets)\n",
    "            print(\"Val: {}\".format(val_loss))\n",
    "            val_losses.append(val_loss)\n",
    "            losses.append(train_loss/n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447.9333"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371.8974472942479"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[np.argmin(val_losses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
