{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# use surprise for collaborative filtering\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# utils\n",
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_path = \"data/final_game_data/\"\n",
    "files = os.listdir(game_data_path)\n",
    "season = pd.read_csv(game_data_path + files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_path + files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_data_path = \"data/odds_data_processed/\"\n",
    "odds_files = os.listdir(odds_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = pd.read_csv(odds_data_path + odds_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = odds.drop(['Unnamed: 0'], axis = 1)\n",
    "odds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_data_path + odds_files[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconciling names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_names = {'Golden State Warriors':'GSW',\n",
    "                'Los Angeles Lakers': 'LAL',\n",
    "                'San Antonio Spurs': 'SAS',\n",
    "                'Cleveland Cavaliers': 'CLE',\n",
    "                'Denver Nuggets': 'DEN',\n",
    "                'Indiana Pacers': 'IND',\n",
    "                'Memphis Grizzlies': 'MEM',\n",
    "                'New Jersey Nets': 'BRK',\n",
    "                'Brooklyn Nets': 'BRK',\n",
    "                'New Orleans Hornets': 'NOP',\n",
    "                'New Orleans Pelicans': 'NOP',\n",
    "                'Orlando Magic': 'ORL',\n",
    "                'Toronto Raptors': 'TOR',\n",
    "                'Miami Heat': 'MIA',\n",
    "                'Seattle SuperSonics': 'SEA',\n",
    "                'Utah Jazz': 'UTA',\n",
    "                'Atlanta Hawks': 'ATL',\n",
    "                'Boston Celtics': 'BOS',\n",
    "                'Charlotte Bobcats': 'CHA',\n",
    "                'Charlotte Hornets': 'CHA',\n",
    "                'Chicago Bulls': 'CHI',\n",
    "                'Los Angeles Clippers': 'LAC',\n",
    "                'Minnesota Timberwolves': 'MIN',\n",
    "                'Phoenix Suns': 'PHO',\n",
    "                'Dallas Mavericks': 'DAL',\n",
    "                'Houston Rockets': 'HOU',\n",
    "                'Milwaukee Bucks': 'MIL',\n",
    "                'Philadelphia 76ers': 'PHI',\n",
    "                'Washington Wizards': 'WAS',\n",
    "                'Detroit Pistons': 'DET',\n",
    "                'New York Knicks': 'NYK',\n",
    "                'Sacramento Kings': 'SAC',\n",
    "                'Portland Trail Blazers': 'POR',\n",
    "                'Oklahoma City Thunder': 'OKC'\n",
    "        }\n",
    "odds_names = {}\n",
    "for name in list(pd.unique(odds.Home)):\n",
    "    found = False\n",
    "    for s_name in season_names:\n",
    "        if name in s_name:\n",
    "            found = True\n",
    "            odds_names[name] = season_names[s_name]\n",
    "    if not found: print(name)\n",
    "odds_names[\"LA Lakers\"] = \"LAL\"\n",
    "odds_names[\"LA Clippers\"] = \"LAC\"\n",
    "odds_names[\"Okla City\"] = \"OKC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds[\"Home\"] = odds[\"Home\"].apply(lambda x: odds_names[x])\n",
    "odds[\"Away\"] = odds[\"Away\"].apply(lambda x: odds_names[x])\n",
    "\n",
    "season[\"team\"] = season[\"team\"].apply(lambda x: season_names[x])\n",
    "season[\"opponent\"] = season[\"opponent\"].apply(lambda x: season_names[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the two data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index(row, col1, col2, col3):\n",
    "    return str(row[col1]) + str(row[col2]) + str(row[col3])\n",
    "\n",
    "def find_category(row):\n",
    "    ref = row[\"Index\"]\n",
    "    if row[\"home\"] == 0:\n",
    "        ref = ref[:-6] + ref[-3:] + ref[-6:-3]\n",
    "    odds_row = odds.loc[odds[\"Index\"] == ref]\n",
    "    #print(list(odds_row[\"Points\"]))\n",
    "    try:\n",
    "        return list(odds_row[\"Points\"])[0]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "season[\"date\"] = season[\"date\"].apply(lambda x: str(x)[:-1])\n",
    "\n",
    "season[\"Index\"] = season.apply(lambda x: make_index(x, \"date\", \"team\", \"opponent\"), axis=1)\n",
    "\n",
    "odds[\"Date\"] = odds[\"Date\"].apply(lambda x: \"\".join(x.split(\"-\")))\n",
    "\n",
    "odds[\"Index\"] = odds.apply(lambda x: make_index(x, \"Date\", \"Home\", \"Away\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season[\"Outcome\"] = season.apply(lambda x: find_category(x), axis = 1) ##### CHANGE THIS TO DEAL WITH OTHER INDICES\n",
    "\n",
    "#merged = merged.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"date\", \"Home\", \"Away\", \"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = season.set_index(\"Index\")\n",
    "in_data = in_data.drop([\"index\", \"Unnamed: 0\"], axis = 1)\n",
    "in_data = in_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for every team: past 3 games stats (them and opponent) + opponent season averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing running season averages by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.unique(in_data.date)\n",
    "\n",
    "season_averages = {}\n",
    "\n",
    "for date in dates:\n",
    "    # get all past games\n",
    "    past_games = in_data[in_data.date < date]\n",
    "    # means\n",
    "    season_averages[date] = past_games.groupby('team').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the past n games for every matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "home_only = in_data[in_data.home == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build a list of games for every team\n",
    "past_n = {}\n",
    "\n",
    "for date in dates:\n",
    "    team_map = {}\n",
    "    past_games = in_data[in_data.date < date]\n",
    "    for team in pd.unique(home_only.team):\n",
    "        #get the past games for team\n",
    "        past_team = past_games[past_games.team == team].tail(3)\n",
    "        team_map[team] = past_team\n",
    "    past_n[date] = team_map        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one-hot encode team names\n",
    "teams = season_names.values()\n",
    "encoding = {}\n",
    "index = 0\n",
    "for team in teams:\n",
    "    if team not in encoding:\n",
    "        encoding[team] = index\n",
    "        index += 1\n",
    "        \n",
    "empty_list = [0 for j in range(index + 1)]\n",
    "encoded = {}\n",
    "for team in teams:\n",
    "    if team in encoded: continue\n",
    "    \n",
    "    copy = empty_list[:]\n",
    "    \n",
    "    i = encoding[team]\n",
    "    copy[i] = 1\n",
    "    encoded[team] = copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, row in home_only.iterrows():\n",
    "    \n",
    "    home_team = row[\"team\"]\n",
    "    away_team = row[\"opponent\"]\n",
    "    \n",
    "    date = row[\"date\"]\n",
    "    \n",
    "    past_n_home = past_n[date][home_team]\n",
    "    past_n_away = past_n[date][away_team]\n",
    "    \n",
    "    avgs = season_averages[date]\n",
    "    \n",
    "    if past_n_home.shape[0] < n or past_n_away.shape[0] < n: continue\n",
    "    \n",
    "    ################ AWAY TEAM PAST GAMES\n",
    "    data_home = []\n",
    "    for j, row_2 in past_n_home.iterrows():\n",
    "        cur_data = []\n",
    "\n",
    "        team = row[\"team\"]\n",
    "        opponent = row[\"opponent\"]\n",
    "\n",
    "        cur_data.extend(encoded[team])\n",
    "        cur_data.extend(encoded[opponent])\n",
    "        cur_data.extend(row.drop([\"team\", \"opponent\", \"date\"]).values)\n",
    "\n",
    "        opp_stats = avgs.loc[opponent].values\n",
    "\n",
    "        cur_data.extend(opp_stats)\n",
    "\n",
    "        data_home.append(cur_data)\n",
    "    \n",
    "    ################ AWAY TEAM PAST GAMES\n",
    "    data_away = []\n",
    "    for j, row_2 in past_n_away.iterrows():\n",
    "        cur_data = []\n",
    "\n",
    "        team = row[\"team\"]\n",
    "        opponent = row[\"opponent\"]\n",
    "\n",
    "        cur_data.extend(encoded[team])\n",
    "        cur_data.extend(encoded[opponent])\n",
    "        cur_data.extend(row.drop([\"team\", \"opponent\", \"date\"]).values)\n",
    "\n",
    "        opp_stats = avgs.loc[opponent].values\n",
    "\n",
    "        cur_data.extend(opp_stats)\n",
    "\n",
    "        data_away.append(cur_data)\n",
    "    \n",
    "    ################ MERGE THE TWO\n",
    "    data = []\n",
    "    for i in range(len(data_home)):\n",
    "        cur_data = data_home[i]\n",
    "        cur_data.extend(data_away[i])\n",
    "        data.append(cur_data)\n",
    "    \n",
    "    X.append(data)\n",
    "    y.append(row[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = X[y > 0]\n",
    "y = y[y > 0]\n",
    "\n",
    "p = np.random.permutation(len(X))\n",
    "X = X[p]\n",
    "y = y[p]\n",
    "\n",
    "val = 0.2\n",
    "val = round(len(X) * val)\n",
    "val_X = X[:val]\n",
    "val_y = y[:val]\n",
    "X = X[val:]\n",
    "y = y[val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Specify the model architecture\n",
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, target_size, num_layers, batch_size, time_steps):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.time_steps = time_steps\n",
    "        \n",
    "        # Initialize LSTM unit\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=False)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2out = nn.Linear(hidden_dim, target_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size , hidden_dim)\n",
    "        return (torch.zeros(self.num_layers, self.time_steps, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.time_steps, self.hidden_dim))\n",
    "        \n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden = self.lstm(input_seq, self.hidden)\n",
    "        \n",
    "        pred = self.hidden2out(lstm_out)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model\n",
    "model = LSTMModel(input_dim = 504,\n",
    "                     hidden_dim = 20,\n",
    "                     target_size = 1,\n",
    "                     num_layers = 1,\n",
    "                     batch_size = 10, \n",
    "                     time_steps = 3)\n",
    "                     \n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(500):   # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    train_loss = 0\n",
    "    for i in range(0, len(X), model.batch_size):\n",
    "        if i + model.batch_size >= len(X) : continue\n",
    "        \n",
    "        #Pytorch accumulates gradients. We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM, detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network.\n",
    "        batch_input = X[i : i + model.batch_size] #.reshape((X.shape[1], model.batch_size, X.shape[2]))\n",
    "        batch = Variable(torch.from_numpy(batch_input)).type(torch.FloatTensor)\n",
    "                                                    \n",
    "        targets = Variable(torch.from_numpy(y[i : i + model.batch_size])).type(torch.FloatTensor)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        scores = model(batch)\n",
    "        scores = scores[:, -1].reshape((model.batch_size)) # we only care about the last output\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().numpy()\n",
    "        \n",
    "    ## validation loss\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(\"----------\")\n",
    "        print(\"Losses after {} iterations:\".format(epoch))\n",
    "        print(\"Train: {}\".format(loss.detach().numpy()))\n",
    "#        with torch.no_grad():\n",
    "#             batch_input = val_X\n",
    "#             batch = Variable(torch.from_numpy(batch_input)).type(torch.FloatTensor)\n",
    "#             targets = Variable(torch.from_numpy(val_y)).type(torch.FloatTensor)\n",
    "#             scores = model(batch)\n",
    "#             scores = scores[:, -1].reshape((len(val_y))) # we only care about the last output\n",
    "#             val_loss = loss_function(scores, targets)\n",
    "#             print(\"Val: {}\".format(val_loss))\n",
    "#             val_losses.append(val_loss)\n",
    "#             losses.append(train_loss/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    batch_input = val_X\n",
    "    batch = Variable(torch.from_numpy(batch_input)).type(torch.FloatTensor)\n",
    "    targets = Variable(torch.from_numpy(val_y)).type(torch.FloatTensor)\n",
    "    scores = model(batch)\n",
    "    scores = scores[:, -1].reshape((len(val_y))) # we only care about the last output\n",
    "    val_loss = loss_function(scores, targets)\n",
    "    print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
