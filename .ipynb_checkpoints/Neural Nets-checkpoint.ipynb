{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# use surprise for collaborative filtering\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_path = \"data/neural_net_data/\"\n",
    "files = os.listdir(game_data_path)\n",
    "with open(game_data_path + files[0], 'rb') as f:\n",
    "    X, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267, 3, 504)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainValSplit(X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X = X[y > 0]\n",
    "    y = y[y > 0]\n",
    "\n",
    "    p = np.random.permutation(len(X))\n",
    "    X = X[p]\n",
    "    y = y[p]\n",
    "\n",
    "    val = 0.2\n",
    "    val = round(len(X) * val)\n",
    "    X_val = X[:val]\n",
    "    y_val = y[:val]\n",
    "    X = X[val:]\n",
    "    y = y[val:]\n",
    "    \n",
    "    return X, y, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_val, y_val = trainValSplit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(y[:,np.newaxis]).type(torch.FloatTensor)\n",
    "X = torch.from_numpy(X.reshape((X.shape[0], -1))).type(torch.FloatTensor)\n",
    "y_val = torch.from_numpy(y_val[:,np.newaxis]).type(torch.FloatTensor)\n",
    "X_val = torch.from_numpy(X_val.reshape((X_val.shape[0], -1))).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[220.],\n",
      "        [196.],\n",
      "        [221.],\n",
      "        [234.],\n",
      "        [214.],\n",
      "        [199.],\n",
      "        [199.],\n",
      "        [191.],\n",
      "        [193.]])\n"
     ]
    }
   ],
   "source": [
    "# Split train/test:\n",
    "print(y[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lin1): Linear(in_features=1512, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=100, bias=True)\n",
      "  (lin3): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (drop1): Dropout(p=0.5)\n",
      "  (drop2): Dropout(p=0.4)\n",
      "  (drop3): Dropout(p=0.25)\n",
      ")\n",
      "Loss=35566.2539\n",
      "Val Loss=18328.8203\n",
      "Loss=1673.8973\n",
      "Val Loss=2457.8010\n",
      "Loss=879.7480\n",
      "Val Loss=1054.4308\n",
      "Loss=700.6231\n",
      "Val Loss=799.0931\n",
      "Loss=613.9303\n",
      "Val Loss=683.0653\n",
      "Loss=564.8362\n",
      "Val Loss=621.2802\n",
      "Loss=529.2913\n",
      "Val Loss=577.1072\n",
      "Loss=495.0400\n",
      "Val Loss=534.9725\n",
      "Loss=468.7276\n",
      "Val Loss=503.0815\n",
      "Loss=443.9324\n",
      "Val Loss=473.0127\n",
      "Loss=426.0743\n",
      "Val Loss=451.5848\n",
      "Loss=406.8761\n",
      "Val Loss=428.6893\n",
      "Loss=389.2118\n",
      "Val Loss=407.7606\n",
      "Loss=376.5348\n",
      "Val Loss=393.1826\n",
      "Loss=366.7103\n",
      "Val Loss=382.3437\n",
      "Loss=354.8146\n",
      "Val Loss=368.7314\n",
      "Loss=344.3857\n",
      "Val Loss=357.1766\n",
      "Loss=338.6741\n",
      "Val Loss=351.2607\n",
      "Loss=333.6332\n",
      "Val Loss=346.2420\n",
      "Loss=326.8127\n",
      "Val Loss=338.7486\n",
      "Loss=320.1507\n",
      "Val Loss=331.6693\n",
      "Loss=313.5034\n",
      "Val Loss=324.6197\n",
      "Loss=307.1900\n",
      "Val Loss=317.7539\n",
      "Loss=302.1994\n",
      "Val Loss=312.7067\n",
      "Loss=298.4177\n",
      "Val Loss=309.0583\n",
      "Loss=294.7684\n",
      "Val Loss=305.4698\n",
      "Loss=289.4366\n",
      "Val Loss=299.8398\n",
      "Loss=285.8111\n",
      "Val Loss=296.3569\n",
      "Loss=282.7921\n",
      "Val Loss=293.4964\n",
      "Loss=278.8613\n",
      "Val Loss=289.4910\n",
      "Loss=274.8077\n",
      "Val Loss=285.4165\n",
      "Loss=272.2710\n",
      "Val Loss=283.0608\n",
      "Loss=270.2812\n",
      "Val Loss=281.4236\n",
      "Loss=267.1762\n",
      "Val Loss=278.3679\n",
      "Loss=264.5836\n",
      "Val Loss=275.8940\n",
      "Loss=262.3368\n",
      "Val Loss=273.8218\n",
      "Loss=258.4737\n",
      "Val Loss=269.8333\n",
      "Loss=257.1471\n",
      "Val Loss=268.8932\n",
      "Loss=254.6729\n",
      "Val Loss=266.6176\n",
      "Loss=253.1289\n",
      "Val Loss=265.3244\n",
      "Loss=251.4050\n",
      "Val Loss=263.8734\n",
      "Loss=248.8493\n",
      "Val Loss=261.3698\n",
      "Loss=247.1382\n",
      "Val Loss=259.8582\n",
      "Loss=244.5542\n",
      "Val Loss=257.2676\n",
      "Loss=242.4323\n",
      "Val Loss=255.2843\n",
      "Loss=240.1240\n",
      "Val Loss=252.9713\n",
      "Loss=238.3620\n",
      "Val Loss=251.3709\n",
      "Loss=236.4323\n",
      "Val Loss=249.5259\n",
      "Loss=234.6336\n",
      "Val Loss=247.9010\n",
      "Loss=232.7023\n",
      "Val Loss=245.9674\n",
      "Loss=230.4580\n",
      "Val Loss=243.7190\n",
      "Loss=226.9958\n",
      "Val Loss=240.0092\n",
      "Loss=225.8508\n",
      "Val Loss=239.0842\n",
      "Loss=224.0096\n",
      "Val Loss=237.2798\n",
      "Loss=221.3323\n",
      "Val Loss=234.5075\n",
      "Loss=219.6505\n",
      "Val Loss=232.8775\n",
      "Loss=217.8295\n",
      "Val Loss=231.0501\n",
      "Loss=215.6427\n",
      "Val Loss=228.8129\n",
      "Loss=213.4163\n",
      "Val Loss=226.5460\n",
      "Loss=212.2353\n",
      "Val Loss=225.5363\n",
      "Loss=210.6609\n",
      "Val Loss=224.0103\n",
      "Loss=208.3789\n",
      "Val Loss=221.6087\n",
      "Loss=206.4998\n",
      "Val Loss=219.6784\n",
      "Loss=203.9124\n",
      "Val Loss=216.9099\n",
      "Loss=202.8191\n",
      "Val Loss=215.9850\n",
      "Loss=201.0961\n",
      "Val Loss=214.2269\n",
      "Loss=199.6648\n",
      "Val Loss=212.8380\n",
      "Loss=198.2036\n",
      "Val Loss=211.3892\n",
      "Loss=195.9584\n",
      "Val Loss=208.9518\n",
      "Loss=192.9802\n",
      "Val Loss=205.6688\n",
      "Loss=190.9749\n",
      "Val Loss=203.5721\n",
      "Loss=189.5578\n",
      "Val Loss=202.1674\n",
      "Loss=188.4894\n",
      "Val Loss=201.1224\n",
      "Loss=186.9146\n",
      "Val Loss=199.4837\n",
      "Loss=184.7825\n",
      "Val Loss=197.2185\n",
      "Loss=183.7257\n",
      "Val Loss=196.2032\n",
      "Loss=182.4409\n",
      "Val Loss=194.9192\n",
      "Loss=180.4949\n",
      "Val Loss=192.7644\n",
      "Loss=178.3818\n",
      "Val Loss=190.5438\n",
      "Loss=177.3436\n",
      "Val Loss=189.5306\n",
      "Loss=175.7799\n",
      "Val Loss=187.8617\n",
      "Loss=173.9812\n",
      "Val Loss=185.9473\n",
      "Loss=172.4417\n",
      "Val Loss=184.3408\n",
      "Loss=171.1854\n",
      "Val Loss=183.0165\n",
      "Loss=169.6077\n",
      "Val Loss=181.3770\n",
      "Loss=168.1016\n",
      "Val Loss=179.7593\n",
      "Loss=166.5205\n",
      "Val Loss=178.0652\n",
      "Loss=164.7914\n",
      "Val Loss=176.1791\n",
      "Loss=162.9120\n",
      "Val Loss=174.1319\n",
      "Loss=161.4791\n",
      "Val Loss=172.5942\n",
      "Loss=160.1502\n",
      "Val Loss=171.1938\n",
      "Loss=158.6540\n",
      "Val Loss=169.5744\n",
      "Loss=157.2441\n",
      "Val Loss=168.0768\n",
      "Loss=155.7214\n",
      "Val Loss=166.4168\n",
      "Loss=154.2510\n",
      "Val Loss=164.8265\n",
      "Loss=152.6659\n",
      "Val Loss=163.1149\n",
      "Loss=151.3132\n",
      "Val Loss=161.6497\n",
      "Loss=150.0062\n",
      "Val Loss=160.2347\n",
      "Loss=148.6345\n",
      "Val Loss=158.7924\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # layer 1 fully connected 150 units\n",
    "        self.lin1 = nn.Linear(n_feature, 500)\n",
    "        \n",
    "        # layer 2 fully connected 50 units\n",
    "        self.lin2 = nn.Linear(500, 100)\n",
    "        \n",
    "        # layer 3 fully connected 1 unit (output)\n",
    "        self.lin3 = nn.Linear(100, n_output)\n",
    "        \n",
    "        # dropouts\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # perform dropout on input vector embeddings\n",
    "        # x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        # x = self.drop2(F.relu(self.lin1(x)))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        # x = self.drop3(F.relu(self.lin2(x)))\n",
    "        x = self.lin3(x)\n",
    "        \n",
    "        return x  \n",
    "\n",
    "net = Net(n_feature=1512, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.000001)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "# plt.ion()   # something about plotting\n",
    "\n",
    "for t in range(5000):\n",
    "    prediction = net(X)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    # Do validation loss\n",
    "    with torch.no_grad():\n",
    "        pred_val = net(X_val)\n",
    "        loss_val = loss_func(pred_val, y_val)\n",
    "\n",
    "    if t % 50 == 0:\n",
    "        # plot and show learning process\n",
    "        '''\n",
    "        plt.cla()\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "        plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)\n",
    "        plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color':  'red'})\n",
    "        plt.pause(0.1)\n",
    "        '''\n",
    "        print(\"-----\")\n",
    "        print(t)\n",
    "        print('Loss=%.4f' % loss.data.numpy())\n",
    "        print('Val Loss=%.4f' % loss_val.data.numpy())\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
